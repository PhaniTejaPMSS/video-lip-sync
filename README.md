# video-lip-sync
A deep learning model that syncs the lip movements of the speaker in a video with the input audio.


# Description
Used wav2lip model for this project which is one of the best models for lip sync of videos for the given audio input given.


# Prerequisites
* `Python ver >= 3.6`
* wav2lip.pth checkpoint file available [here](https://drive.google.com/file/d/1qqILzf-Q2lE4k5FjzoEpLna5F3vTGVU9/view?usp=sharing)


# Steps to run the model 
* Clone or download this repository in your system or in google colab.
* Save the model checkpoint given in the repo at an appropriate location and change the location of it while running the model.
* If you are running in your local system, it is suggested to use python virtual environment `python -m venv myvenv`

